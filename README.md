<div align="center">

# ğŸ“š RAG Chatbot

### *Your Documents. Your Questions. Instant AI-Powered Answers.*

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.9%2B-blue)](https://www.python.org/)
[![React](https://img.shields.io/badge/react-19.2-61dafb)](https://reactjs.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109%2B-009688)](https://fastapi.tiangolo.com/)
[![Tailwind CSS](https://img.shields.io/badge/Tailwind-4.0-38B2AC)](https://tailwindcss.com/)
[![LangChain](https://img.shields.io/badge/LangChain-Integration-orange)](https://langchain.com/)
[![Google Gemini](https://img.shields.io/badge/Google-Gemini-4285F4)](https://ai.google.dev/)

[Quick Start](#-quick-start) â€¢ [Features](#-features) â€¢ [Architecture](#-architecture) â€¢ [API Docs](#-api-reference) â€¢ [Contributing](#-contributing)

---

</div>

## ğŸŒŸ What is RAG Chatbot?

**RAG Chatbot** is a cutting-edge **Retrieval-Augmented Generation (RAG)** application that transforms how you interact with your documents. Upload any PDF, and engage in intelligent, context-aware conversations powered by Google's Gemini AI.

Unlike traditional chatbots, RAG Chatbot **doesn't hallucinate** â€” it answers based *strictly* on the content of your uploaded documents, combining the power of semantic search with advanced language models.

### ğŸ¯ Why RAG Chatbot?

- âœ… **100% Context-Grounded**: Answers derived exclusively from your documents
- âš¡ **Lightning Fast**: Optimized retrieval with FAISS vector database
- ğŸ¨ **Premium UI/UX**: Glassmorphism design with smooth animations
- ğŸ”’ **Privacy-First**: Process documents locally with no data persistence on restart
- ğŸ§  **Smart Chunking**: Advanced document processing for optimal retrieval
- ğŸ”„ **Real-Time Streaming**: Watch responses generate live, word by word

### ğŸ’¡ Use Cases

- ğŸ“„ **Research**: Query academic papers, reports, and documentation
- ğŸ“š **Education**: Interactive learning from textbooks and study materials
- ğŸ’¼ **Business**: Analyze contracts, proposals, and technical documents
- ğŸ“– **Personal**: Explore books, manuals, and guides conversationally

---

## âœ¨ Features

### ğŸ§  Intelligent Backend

| Feature | Description |
|---------|-------------|
| **ğŸ¤– Google Gemini Integration** | Powered by `gemini-flash-latest` for ultra-fast, accurate responses |
| **ğŸ” Advanced RAG Pipeline** | Semantic chunking (800 chars, 400 overlap) + Gecko embeddings |
| **ğŸ’¾ Vector Search** | FAISS CPU-optimized indexing with k=7 retrieval |
| **ğŸ“‘ Robust PDF Processing** | Magic byte validation, 50MB limit, secure temp storage |
| **ğŸ’¬ Session Management** | SQLite-based chat history with full persistence |
| **ğŸ”„ Auto-Reset** | Session and index auto-clear on server restart |
| **ğŸ›¡ï¸ Security** | Rate limiting (30 req/min chat, 10 req/min upload) + request tracing |
| **ğŸ“Š Structured Logging** | Production-ready logging with `structlog` |
| **ğŸ§ª Tested** | Comprehensive pytest suite for ingestion, RAG, and API |

### ğŸ¨ Premium Frontend

| Feature | Description |
|---------|-------------|
| **âœ¨ Glassmorphism Design** | Modern blur effects, gradients, and depth |
| **ğŸ¬ Startup Animation** | Smooth logo intro with motion transitions |
| **ğŸ’¬ Real-Time Streaming** | Server-Sent Events (SSE) for live response rendering |
| **ğŸ“ Markdown Support** | Full syntax highlighting with `react-markdown` + `remark-gfm` |
| **ğŸ“± Fully Responsive** | Optimized for desktop, tablet, and mobile |
| **âš¡ Optimized Caching** | TanStack Query for efficient data fetching |
| **ğŸ¯ Smart UX** | Auto-scroll, skeleton loaders, error boundaries |
| **ğŸ–¼ï¸ Custom Icons** | Lucide React icons with WebP-optimized assets |

### ğŸ” Security & Performance

- **Rate Limiting**: Prevents API abuse with configurable limits
- **Request ID Tracing**: Every request tracked for debugging
- **Input Validation**: Pydantic models for type-safe APIs
- **CORS Protection**: Whitelist-based origin control
- **Exponential Backoff**: Retry logic for transient failures
- **Session Isolation**: Clean state on every restart

---

## ğŸ—ï¸ Architecture

RAG Chatbot follows a modern **client-server architecture** with a sophisticated RAG pipeline:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INTERFACE                          â”‚
â”‚  React + Vite + Tailwind CSS + Framer Motion + TanStack Query  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ HTTP/SSE
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FASTAPI BACKEND                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Routers    â”‚  â”‚  Middleware  â”‚  â”‚   State Manager     â”‚  â”‚
â”‚  â”‚ /upload      â”‚  â”‚ - Rate Limit â”‚  â”‚ - Session State     â”‚  â”‚
â”‚  â”‚ /chat        â”‚  â”‚ - Request ID â”‚  â”‚ - Vector Store Ref  â”‚  â”‚
â”‚  â”‚ /history     â”‚  â”‚ - CORS       â”‚  â”‚                     â”‚  â”‚
â”‚  â”‚ /reset       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚
â”‚                             â”‚                                   â”‚
â”‚                             â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                  RAG PIPELINE (LangChain)                â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  PDF   â”‚â”€â”€â–¶â”‚ Chunk  â”‚â”€â”€â–¶â”‚  Embed   â”‚â”€â”€â–¶â”‚  FAISS   â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ Loader â”‚   â”‚ (800)  â”‚   â”‚ (Gecko)  â”‚   â”‚  Index   â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚                                                  â”‚        â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚        â”‚  â”‚
â”‚  â”‚  â”‚  Query  â”€â”€â–¶  Retrieve (k=7)  â”€â”€â–¶  Gemini  â”‚ â”‚        â”‚  â”‚
â”‚  â”‚  â”‚                                    Flash   â”‚â—€â”˜        â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   SQLite     â”‚                           â”‚  Temp Storage  â”‚ â”‚
â”‚  â”‚ Chat History â”‚                           â”‚  (PDF Upload)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ RAG Pipeline Workflow

1. **ğŸ“¤ Document Ingestion**
   - User uploads PDF â†’ Validated (magic bytes, size)
   - PyPDF extracts text â†’ Cleaned and normalized
   - RecursiveCharacterTextSplitter creates chunks (800/400)

2. **ğŸ§® Embedding & Indexing**
   - Google Gecko (`text-embedding-004`) generates vectors
   - FAISS CPU index stores embeddings
   - Metadata preserved for source tracking

3. **ğŸ’¬ Query Processing**
   - User question â†’ Embedded with same model
   - FAISS retrieves top 7 most relevant chunks
   - Context + question sent to Gemini Flash

4. **ğŸ¤– Response Generation**
   - Gemini generates grounded answer
   - Streamed back via SSE
   - Stored in SQLite chat history

### ğŸ› ï¸ Technology Justifications

| Technology | Why? |
|------------|------|
| **Google Gemini Flash** | Sub-second latency, built-in streaming, cost-effective |
| **FAISS** | Industry-standard vector search, CPU-optimized, no external dependencies |
| **LangChain** | Abstracts RAG complexity, modular pipeline, extensive integrations |
| **FastAPI** | Native async support, auto-generated docs, Pydantic validation |
| **React + Vite** | Lightning-fast HMR, modern tooling, optimal bundle size |
| **TailwindCSS 4** | Zero-runtime, CSS-first approach, perfect for premium UIs |

---

## ğŸš€ Quick Start

Get up and running in **3 minutes**!

### Prerequisites

Ensure you have the following installed:

- **Python 3.9+** â€” [Download](https://www.python.org/downloads/)
- **Node.js 18+** â€” [Download](https://nodejs.org/)
- **Google API Key** â€” [Get one here](https://aistudio.google.com/app/apikey)

### Installation

#### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/yugam23/RAG-Chatbot.git
cd RAG-Chatbot
```

#### 2ï¸âƒ£ Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

**Configure Environment:**

Create a `.env` file in `backend/`:

```env
# backend/.env
GOOGLE_API_KEY=your_actual_api_key_here
ALLOWED_ORIGINS=http://localhost:5173
```

**Run the Backend:**

```bash
python main.py
# ğŸš€ Server running at http://localhost:8000
# ğŸ“– API Docs at http://localhost:8000/docs
```

#### 3ï¸âƒ£ Frontend Setup

Open a **new terminal**:

```bash
cd frontend

# Install dependencies
npm install

# Start development server
npm run dev
# âœ¨ App running at http://localhost:5173
```

### âœ… Verification

1. Open [http://localhost:5173](http://localhost:5173)
2. You should see the **splash screen animation**
3. Backend health check: [http://localhost:8000/health](http://localhost:8000/health)
4. API Documentation: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ“‚ Project Structure

```
RAG-Chatbot/
â”œâ”€â”€ ğŸ“ backend/                     # FastAPI Python Backend
â”‚   â”œâ”€â”€ ğŸ“ routers/                 # API Route Handlers
â”‚   â”‚   â”œâ”€â”€ upload.py               # PDF upload & indexing endpoint
â”‚   â”‚   â””â”€â”€ chat.py                 # Chat streaming & history endpoints
â”‚   â”œâ”€â”€ ğŸ“ tests/                   # Pytest Test Suite
â”‚   â”‚   â”œâ”€â”€ conftest.py             # Test fixtures & config
â”‚   â”‚   â”œâ”€â”€ test_api.py             # API integration tests
â”‚   â”‚   â”œâ”€â”€ test_ingestion.py       # PDF processing tests
â”‚   â”‚   â””â”€â”€ test_rag.py             # RAG pipeline tests
â”‚   â”œâ”€â”€ ğŸ“ temp/                    # Temporary PDF storage
â”‚   â”œâ”€â”€ ğŸ“ faiss_index/             # Vector database (generated)
â”‚   â”œâ”€â”€ config.py                   # Centralized configuration
â”‚   â”œâ”€â”€ database.py                 # SQLite async operations
â”‚   â”œâ”€â”€ ingestion.py                # Document processing pipeline
â”‚   â”œâ”€â”€ rag.py                      # RAG chain implementation
â”‚   â”œâ”€â”€ state.py                    # Application state management
â”‚   â”œâ”€â”€ middleware.py               # Rate limiting & request tracking
â”‚   â”œâ”€â”€ logging_config.py           # Structured logging setup
â”‚   â”œâ”€â”€ models.py                   # Pydantic models
â”‚   â”œâ”€â”€ main.py                     # FastAPI app entry point
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚   â”œâ”€â”€ pytest.ini                  # Pytest configuration
â”‚   â”œâ”€â”€ mypy.ini                    # Type checking config
â”‚   â””â”€â”€ chat_history.db             # SQLite database (generated)
â”‚
â”œâ”€â”€ ğŸ“ frontend/                    # React + Vite Frontend
â”‚   â”œâ”€â”€ ğŸ“ src/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ components/          # React Components
â”‚   â”‚   â”‚   â”œâ”€â”€ Header.jsx          # App header with upload/reset
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatArea.jsx        # Message display area
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatMessage.jsx     # Individual message component
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInput.jsx       # User input with send button
â”‚   â”‚   â”‚   â”œâ”€â”€ SplashScreen.jsx    # Startup animation
â”‚   â”‚   â”‚   â”œâ”€â”€ Skeleton.jsx        # Loading placeholder
â”‚   â”‚   â”‚   â”œâ”€â”€ ErrorBoundary.jsx   # Error handling wrapper
â”‚   â”‚   â”‚   â”œâ”€â”€ MarkdownComponents.jsx  # Markdown renderers
â”‚   â”‚   â”‚   â””â”€â”€ index.js            # Component exports
â”‚   â”‚   â”œâ”€â”€ ğŸ“ hooks/               # Custom React Hooks
â”‚   â”‚   â”‚   â”œâ”€â”€ useChat.js          # Chat state & streaming logic
â”‚   â”‚   â”‚   â””â”€â”€ useApiQueries.js    # TanStack Query hooks
â”‚   â”‚   â”œâ”€â”€ ğŸ“ services/            # API Communication
â”‚   â”‚   â”‚   â””â”€â”€ api.js              # HTTP client & endpoints
â”‚   â”‚   â”œâ”€â”€ ğŸ“ context/             # React Context Providers
â”‚   â”‚   â”‚   â””â”€â”€ ChatContext.jsx     # Global chat state
â”‚   â”‚   â”œâ”€â”€ App.jsx                 # Main App component
â”‚   â”‚   â”œâ”€â”€ main.jsx                # React entry point
â”‚   â”‚   â””â”€â”€ index.css               # Global styles & theme
â”‚   â”œâ”€â”€ ğŸ“ public/                  # Static Assets
â”‚   â”‚   â”œâ”€â”€ chatbot.png             # App logo (WebP)
â”‚   â”‚   â”œâ”€â”€ message.png             # Message icon
â”‚   â”‚   â””â”€â”€ clear_chat.png          # Clear icon
â”‚   â”œâ”€â”€ index.html                  # HTML template
â”‚   â”œâ”€â”€ package.json                # Node dependencies
â”‚   â”œâ”€â”€ vite.config.js              # Vite configuration
â”‚   â”œâ”€â”€ tailwind.config.js          # Tailwind CSS config
â”‚   â”œâ”€â”€ postcss.config.js           # PostCSS setup
â”‚   â””â”€â”€ eslint.config.js            # ESLint rules
â”‚
â”œâ”€â”€ ğŸ“„ README.md                    # This file!
â”œâ”€â”€ ğŸ“„ LICENSE                      # MIT License
â””â”€â”€ ğŸ“ .git/                        # Git repository
```

---

## âš™ï¸ Configuration

### Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `GOOGLE_API_KEY` | âœ… Yes | â€” | Google AI API key for Gemini & Gecko |
| `ALLOWED_ORIGINS` | âŒ No | `http://localhost:5173,http://localhost:5174` | Comma-separated CORS origins |

### Advanced Configuration

Edit `backend/config.py` to tune performance:

```python
# Document Processing
CHUNK_SIZE = 800              # Characters per chunk
CHUNK_OVERLAP = 400           # Overlap between chunks

# Retrieval
RETRIEVER_K = 7               # Number of chunks to retrieve

# Models
EMBEDDING_MODEL = "models/text-embedding-004"  # Gecko embeddings
LLM_MODEL = "gemini-flash-latest"              # Gemini model
LLM_TEMPERATURE = 0.0         # 0 = deterministic, 1 = creative

# Security
MAX_FILE_SIZE_MB = 50         # Maximum PDF size
RATE_LIMIT_UPLOADS = 10       # Uploads per minute
RATE_LIMIT_CHAT = 30          # Chat requests per minute

# Ingestion Retry Strategy
INGESTION_MAX_RETRIES = 5     # Embedding retry attempts
INGESTION_BASE_DELAY = 2      # Initial retry delay (seconds)
INGESTION_BATCH_SIZE = 10     # Chunks per batch
```

### Performance Tuning Tips

ğŸ’¡ **For Larger Documents:**
- Increase `CHUNK_SIZE` to 1000-1200
- Increase `RETRIEVER_K` to 10-12

âš¡ **For Faster Responses:**
- Decrease `RETRIEVER_K` to 5
- Consider switching to `gemini-flash-thinking` for complex queries

ğŸ¯ **For More Accurate Answers:**
- Decrease `CHUNK_SIZE` to 600 (more granular chunks)
- Increase `CHUNK_OVERLAP` to 200 (better context preservation)

---

## ğŸ“¡ API Reference

Full interactive documentation available at **[http://localhost:8000/docs](http://localhost:8000/docs)** when running.

### Endpoints Overview

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | Health check |
| `POST` | `/upload` | Upload & index PDF |
| `POST` | `/chat` | Stream chat response |
| `GET` | `/history` | Retrieve chat history |
| `POST` | `/clear-chat` | Clear chat (keep document) |
| `POST` | `/reset` | Full session reset |

---

### `POST /upload`

Upload and index a PDF document.

**Request:**

```bash
curl -X POST http://localhost:8000/upload \
  -F "file=@document.pdf"
```

**Success Response (200):**

```json
{
  "message": "PDF uploaded and indexed successfully",
  "filename": "document.pdf",
  "chunks": 42,
  "upload_time": "2026-01-17T12:00:00Z"
}
```

**Error Response (400):**

```json
{
  "detail": "Invalid file type. Only PDF files are allowed."
}
```

**Validations:**
- âœ… File extension must be `.pdf`
- âœ… File must start with magic bytes `%PDF`
- âœ… File size â‰¤ 50MB
- âœ… Rate limited to 10 uploads/minute

---

### `POST /chat`

Stream a chat response based on uploaded document.

**Request:**

```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "What are the key findings?",
    "session_id": "optional-session-id"
  }'
```

**Response (Server-Sent Events):**

```
data: {"type": "token", "content": "The"}
data: {"type": "token", "content": " key"}
data: {"type": "token", "content": " findings"}
data: {"type": "token", "content": " are"}
data: {"type": "done"}
```

**Error Response (400):**

```json
{
  "detail": "No documents indexed. Please upload a PDF first."
}
```

**Notes:**
- Streams via SSE (Server-Sent Events)
- Rate limited to 30 requests/minute
- Automatically saves to chat history

---

### `GET /history`

Retrieve all chat messages for the current session.

**Request:**

```bash
curl http://localhost:8000/history
```

**Response (200):**

```json
{
  "messages": [
    {
      "id": 1,
      "role": "user",
      "content": "What are the key findings?",
      "timestamp": "2026-01-17T12:00:00Z"
    },
    {
      "id": 2,
      "role": "assistant",
      "content": "The key findings are...",
      "timestamp": "2026-01-17T12:00:05Z"
    }
  ]
}
```

---

### `POST /clear-chat`

Clear chat history while preserving the indexed document.

**Request:**

```bash
curl -X POST http://localhost:8000/clear-chat
```

**Response (200):**

```json
{
  "message": "Chat history cleared successfully"
}
```

---

### `POST /reset`

Complete session reset: clears chat history AND indexed documents.

**Request:**

```bash
curl -X POST http://localhost:8000/reset
```

**Response (200):**

```json
{
  "message": "Session reset successfully"
}
```

**Effect:**
- âŒ Deletes all chat messages
- âŒ Removes FAISS vector index
- âŒ Clears uploaded document reference
- âœ… Requires re-uploading a PDF before chatting again

---

## ğŸ® Usage Guide

### Step-by-Step Walkthrough

#### 1. ğŸš€ Launch the Application

Open [http://localhost:5173](http://localhost:5173). You'll see the **animated splash screen** with the chatbot logo transitioning smoothly into position.

#### 2. ğŸ“¤ Upload Your Document

- Click the **ğŸ“ Upload PDF** button in the top-right header
- Select a PDF file (max 50MB)
- Wait for the upload confirmation toast
- The filename will appear in the header

#### 3. ğŸ’¬ Start Chatting

Once uploaded, the chat interface activates:

- Type your question in the input field at the bottom
- Press **Enter** or click the **Send** button
- Watch the AI response stream in real-time
- Markdown formatting is fully supported (code blocks, lists, tables, etc.)

#### 4. ğŸ§¹ Manage Your Session

**Clear Chat History** (keeps document):
- Click the **Clear Chat** button in the header
- Chat messages are wiped, but you can continue asking questions about the same document

**New Chat** (complete reset):
- Click the **New Chat** button
- Removes both chat history AND the indexed document
- You'll need to re-upload a PDF

### ğŸ’¡ Pro Tips

- **Specific Questions**: The more specific your question, the better the answer
- **Sequential Queries**: Build on previous questions for deeper insights
- **Code/Tables**: The UI beautifully renders code blocks and markdown tables
- **Long Documents**: For 100+ page PDFs, consider asking about specific sections first

---

## ğŸ§ª Testing

The backend includes a comprehensive pytest suite.

### Run All Tests

```bash
cd backend
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Run all tests
pytest

# Run with verbose output
pytest -v

# Run specific test file
pytest tests/test_api.py

# Run with coverage report
pytest --cov=. --cov-report=html
```

### Test Coverage

| Module | Coverage |
|--------|----------|
| `ingestion.py` | PDF processing, chunking, embedding |
| `rag.py` | Retrieval chain, query processing |
| `routers/upload.py` | Upload endpoint, validation |
| `routers/chat.py` | Chat streaming, history |

### Running Frontend Linting

```bash
cd frontend

# Run ESLint
npm run lint

# Auto-fix issues
npm run lint -- --fix
```

---

## ğŸ› Troubleshooting

### Common Issues & Solutions

#### âŒ Backend: `ValidationError: GOOGLE_API_KEY field required`

**Cause**: Missing or invalid `.env` file.

**Solution**:
```bash
cd backend
echo "GOOGLE_API_KEY=your_key_here" > .env
```

---

#### âŒ Frontend: `Failed to fetch` or CORS errors

**Cause**: Backend not running or CORS misconfiguration.

**Solution**:
1. Ensure backend is running: `http://localhost:8000/health` should return `{"status": "healthy"}`
2. Check `ALLOWED_ORIGINS` in `backend/.env` includes `http://localhost:5173`
3. Restart the backend after changing `.env`

---

#### âŒ Upload: `Invalid file type`

**Cause**: File doesn't have PDF magic bytes or has wrong extension.

**Solution**:
- Ensure file is a **valid PDF** (not a renamed document)
- Try opening the PDF in a viewer first to confirm it's not corrupted

---

#### âŒ Chat: `No documents indexed`

**Cause**: PDF failed to upload or session was reset.

**Solution**:
1. Check backend logs for upload errors
2. Re-upload the PDF
3. Verify `backend/faiss_index/` directory exists

---

#### âŒ Slow Responses

**Cause**: Large document or many chunks retrieved.

**Solution**:
- **Short-term**: Reduce `RETRIEVER_K` in `config.py` (e.g., from 7 to 5)
- **Long-term**: Consider chunking optimization (increase `CHUNK_SIZE`)

---

#### âŒ Rate Limit Exceeded

**Cause**: Too many requests in a short time.

**Solution**:
- Wait 60 seconds for the rate limit to reset
- Adjust `RATE_LIMIT_CHAT` or `RATE_LIMIT_UPLOADS` in `config.py` if needed

---

### Debug Mode

Enable detailed logging:

1. **Backend Logs**: Already enabled via `structlog` â€” check console output
2. **Frontend Errors**: Open browser DevTools (F12) â†’ Console tab
3. **Network Issues**: DevTools â†’ Network tab â†’ check failed requests

---

## ğŸš€ Deployment

### Production Checklist

- [ ] Set `GOOGLE_API_KEY` in production environment
- [ ] Update `ALLOWED_ORIGINS` to production domain
- [ ] Disable `reload=True` in `uvicorn.run()` (main.py)
- [ ] Use a production WSGI server (e.g., Gunicorn)
- [ ] Set up HTTPS with SSL certificates
- [ ] Configure a reverse proxy (Nginx, Traefik)
- [ ] Set up persistent storage for `chat_history.db` and `faiss_index/`
- [ ] Implement proper logging aggregation (e.g., ELK stack)
- [ ] Set up monitoring (uptime, error rates)

### Example: Deploy with Docker (Future Enhancement)

```dockerfile
# Dockerfile (not included yet â€” coming soon!)
FROM python:3.11-slim
WORKDIR /app
COPY backend/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY backend/ .
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

---

## ğŸ›£ï¸ Roadmap

### Planned Features

- [ ] ğŸ³ **Docker Support**: One-command deployment with Docker Compose
- [ ] ğŸ“Š **Multi-Document Support**: Upload and query multiple PDFs simultaneously
- [ ] ğŸ” **Source Citations**: Show which document chunks were used for each answer
- [ ] ğŸ“¥ **Export Chat**: Download conversation history as JSON/PDF
- [ ] ğŸŒ™ **Dark/Light Mode Toggle**: User-selectable themes
- [ ] ğŸ”— **URL Ingestion**: Support web pages and articles, not just PDFs
- [ ] ğŸ§  **Advanced Models**: Support for GPT-4, Claude, and local LLMs
- [ ] ğŸ” **User Authentication**: Multi-user support with sessions
- [ ] ğŸ“ˆ **Analytics Dashboard**: Query insights and usage stats
- [ ] ğŸŒ **Internationalization**: Multi-language support

### Community Requests

Have an idea? [Open an issue](https://github.com/yugam23/RAG-Chatbot/issues) with the `enhancement` label!

---

## ğŸ¤ Contributing

Contributions are **highly welcome**! This project follows standard open-source practices.

### How to Contribute

1. **Fork** the repository
2. **Create** a feature branch:
   ```bash
   git checkout -b feature/amazing-feature
   ```
3. **Make** your changes with clear, descriptive commits:
   ```bash
   git commit -m "Add source citation feature"
   ```
4. **Push** to your branch:
   ```bash
   git push origin feature/amazing-feature
   ```
5. **Open** a Pull Request with a detailed description

### Development Guidelines

- âœ… Follow existing code style (use `black` for Python, `prettier` for JS)
- âœ… Add tests for new features
- âœ… Update documentation (README, docstrings)
- âœ… Ensure all tests pass before submitting PR
- âœ… Keep commits atomic and well-described

### Code of Conduct

Be respectful, inclusive, and constructive. We're all here to learn and build together!

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

```
MIT License

Copyright (c) 2026 Yugam

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
```

---

## ğŸ™ Acknowledgments

This project is built on the shoulders of giants. Special thanks to:

- **[Google AI](https://ai.google.dev/)** â€” For the incredible Gemini and Gecko models
- **[LangChain](https://langchain.com/)** â€” For abstracting RAG complexity
- **[FastAPI](https://fastapi.tiangolo.com/)** â€” For the lightning-fast async framework
- **[React](https://reactjs.org/)** â€” For the powerful component model
- **[FAISS](https://github.com/facebookresearch/faiss)** â€” For efficient vector search
- **[TailwindCSS](https://tailwindcss.com/)** â€” For the utility-first styling paradigm

And to the amazing **open-source community** for continuous inspiration!

---

## â­ Show Your Support

If you found this project helpful, consider giving it a **â­ star** on GitHub!

It helps others discover the project and motivates continued development.

---

<div align="center">

**Made with â¤ï¸ by [Yugam](https://github.com/yugam23)**

[â¬† Back to Top](#-rag-chatbot)

</div>
